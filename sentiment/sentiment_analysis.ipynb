{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Sentiment Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python -m spacy download de_core_news_sm\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import itertools\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim import corpora, similarities\n",
    "from gensim.matutils import sparse2full\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from IPython.display import display\n",
    "from PyPDF2 import PdfReader\n",
    "from transformers import LongformerTokenizer, LongformerModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Extract Manifestos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spacy.load(\"de_core_news_sm\")\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    num_pages = len(reader.pages)\n",
    "    full_text = ''\n",
    "\n",
    "    for page_num in range(num_pages):\n",
    "        page = reader.pages[page_num]\n",
    "        text = page.extract_text()\n",
    "        full_text += text\n",
    "\n",
    "    return full_text\n",
    "\n",
    "cdu_text = extract_text_from_pdf('../manifestos/cdu_csu.pdf')\n",
    "with open('../manifestos/cdu_csu_text.txt', 'w', encoding='utf-8') as file:\n",
    "    file.write(cdu_text)\n",
    "\n",
    "spd_text = extract_text_from_pdf('../manifestos/spd.pdf')\n",
    "with open('../manifestos/spd_text.txt', 'w', encoding='utf-8') as file:\n",
    "    file.write(spd_text)\n",
    "\n",
    "gruene_text = extract_text_from_pdf('../manifestos/gruene.pdf')\n",
    "with open('../manifestos/gruene_text.txt', 'w', encoding='utf-8') as file:\n",
    "    file.write(gruene_text)\n",
    "\n",
    "afd_text = extract_text_from_pdf('../manifestos/afd.pdf')\n",
    "with open('../manifestos/afd_text.txt', 'w', encoding='utf-8') as file:\n",
    "    file.write(afd_text)\n",
    "\n",
    "linke_text = extract_text_from_pdf('../manifestos/linke.pdf')\n",
    "with open('../manifestos/linke_text.txt', 'w', encoding='utf-8') as file:\n",
    "    file.write(linke_text)\n",
    "    \n",
    "fdp_text = extract_text_from_pdf('../manifestos/fdp.pdf')\n",
    "with open('../manifestos/fdp_text.txt', 'w', encoding='utf-8') as file:\n",
    "    file.write(fdp_text)\n",
    "\n",
    "party_docs = []\n",
    "party_docs.append(cdu_text)\n",
    "party_docs.append(spd_text)\n",
    "party_docs.append(gruene_text)\n",
    "party_docs.append(afd_text)\n",
    "party_docs.append(linke_text)\n",
    "party_docs.append(fdp_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.nlp = spacy.load(\"de_core_news_sm\")\n",
    "    \n",
    "    def tokenize_documents(self, documents):\n",
    "        tokenized_docs = []\n",
    "        for doc in documents:\n",
    "            doc_tokens = self.nlp(doc)\n",
    "            tokenized_tokens = [token.text for token in doc_tokens]\n",
    "            tokenized_docs.append(tokenized_tokens)\n",
    "        return tokenized_docs\n",
    "    \n",
    "    def remove_tags(self, tokenized_docs):\n",
    "        without_tag_docs = []\n",
    "        \n",
    "        for doc_tokens in tokenized_docs:\n",
    "            cleaned_tokens = [token.strip().replace('\\n', '') for token in doc_tokens if token.strip().replace('\\n', '') not in ['\\n', '']]\n",
    "            without_tag_docs.append(cleaned_tokens)\n",
    "        return without_tag_docs\n",
    "    \n",
    "    def lemmatize_documents(self, tokenized_docs):\n",
    "        lemmatized_docs = []\n",
    "        for doc_tokens in tokenized_docs:\n",
    "            lemmatized_tokens = [token.lemma_ for token in self.nlp(' '.join(doc_tokens))]\n",
    "            lemmatized_docs.append(lemmatized_tokens)\n",
    "        return lemmatized_docs\n",
    "    \n",
    "    def remove_stopwords_punctuations_numbers(self, lemmatized_docs):\n",
    "        clean_docs = []\n",
    "        for lemmatized_tokens in lemmatized_docs:\n",
    "            lemmatized_tokens_no_stopwords = [token for token in lemmatized_tokens if not self.nlp.vocab[token].is_stop]\n",
    "            lemmatized_tokens_no_punct = [token for token in lemmatized_tokens_no_stopwords if not self.nlp.vocab[token].is_punct]\n",
    "            lemmatized_tokens_no_nums = [token for token in lemmatized_tokens_no_punct if not self.nlp.vocab[token].like_num]\n",
    "            clean_docs.append(lemmatized_tokens_no_nums)\n",
    "        return clean_docs\n",
    "\n",
    "preprocessor = TextPreprocessor()\n",
    "\n",
    "# Tokenization\n",
    "tokenized = preprocessor.tokenize_documents(party_docs)\n",
    "\n",
    "# Clear Tags\n",
    "tag_cleared = preprocessor.remove_tags(tokenized)\n",
    "\n",
    "# Lemmatization\n",
    "lemmatized = preprocessor.lemmatize_documents(tag_cleared)\n",
    "\n",
    "# Removing Stopwords, Punctuation, and Numbers\n",
    "cleaned = preprocessor.remove_stopwords_punctuations_numbers(lemmatized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Sentiment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### German Sentiment Model\n",
    "\n",
    "https://huggingface.co/oliverguhr/german-sentiment-bert?text=Da+sisrt+super"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Paragraph Sentiment     Score\n",
      "0     Das Programm für Stabilität   \\n   und Erneuer...   neutral  0.999025\n",
      "1                                         GEMEINSAM FÜR   neutral  0.479474\n",
      "2                                          EIN MODERNES  positive  0.993092\n",
      "3                                          DEUTSCHLAND.  positive  0.872862\n",
      "4     Seite 1 von 139 Inhaltsverzeichnis \\n \\nEinlei...   neutral  0.999956\n",
      "...                                                 ...       ...       ...\n",
      "3866                                          4994  \\n•  positive  0.903174\n",
      "3867  Wir unterstützen die Bewerbungen für internati...   neutral  0.999980\n",
      "3868  Diese müssen ökologisch, ökonomisch und sozial...   neutral  0.999991\n",
      "3869  Das ist auch der M aßstab für eine 4997  \\nBew...   neutral  0.999945\n",
      "3870                                               4998  positive  0.904764\n",
      "\n",
      "[3871 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from germansentiment import SentimentModel\n",
    "\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "with open('../manifestos/cdu_csu_text.txt', 'r', encoding='utf-8') as file:\n",
    "    manifesto_text = file.read()\n",
    "\n",
    "doc = nlp(manifesto_text)\n",
    "paragraphs = [p.text.strip() for p in doc.sents if len(p.text.strip()) > 1] \n",
    "\n",
    "data = {'Paragraph': [], 'Sentiment': [], 'Score': []}\n",
    "\n",
    "model = SentimentModel()\n",
    "\n",
    "for paragraph in paragraphs:\n",
    "    pred_class, probabilities = model.predict_sentiment([paragraph], output_probabilities=True)\n",
    "    max_probability = max(probabilities[0], key=lambda x: x[1])[1]\n",
    "    \n",
    "    data['Paragraph'].append(paragraph)\n",
    "    data['Sentiment'].append(pred_class[0])\n",
    "    data['Score'].append(max_probability)\n",
    "\n",
    "# Erstellung eines DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Ausgabe des DataFrame\n",
    "print(df)\n",
    "\n",
    "# Speichern des DataFrames in einer CSV-Datei\n",
    "df.to_csv('sentiment_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EIN MODERNES</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.993092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DEUTSCHLAND.</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.872862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>.................................................</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.937838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>.................................................</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.956889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Neue Aufmerksamkeit für den asiatisch-pazifisc...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.985758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3858</th>\n",
       "      <td>4985  \\n•</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.909667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3860</th>\n",
       "      <td>4987  \\n•</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.907502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3863</th>\n",
       "      <td>4991  \\n•</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.911100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3866</th>\n",
       "      <td>4994  \\n•</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.903174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3870</th>\n",
       "      <td>4998</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.904764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>759 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Paragraph Sentiment     Score\n",
       "2                                          EIN MODERNES  positive  0.993092\n",
       "3                                          DEUTSCHLAND.  positive  0.872862\n",
       "5     .................................................  positive  0.937838\n",
       "10    .................................................  positive  0.956889\n",
       "12    Neue Aufmerksamkeit für den asiatisch-pazifisc...  positive  0.985758\n",
       "...                                                 ...       ...       ...\n",
       "3858                                          4985  \\n•  positive  0.909667\n",
       "3860                                          4987  \\n•  positive  0.907502\n",
       "3863                                          4991  \\n•  positive  0.911100\n",
       "3866                                          4994  \\n•  positive  0.903174\n",
       "3870                                               4998  positive  0.904764\n",
       "\n",
       "[759 rows x 3 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Sentiment == \"positive\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
